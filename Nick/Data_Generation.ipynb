{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#2 means reload everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lhapdf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import functions_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataANN(object):\n",
    "    def __init__(self, pdfset='cteq61',\n",
    "                 ff_PIp='NNFF10_PIp_nlo', ff_PIm='NNFF10_PIm_nlo', ff_PIsum='NNFF10_PIsum_nlo',\n",
    "                 ff_KAp='NNFF10_KAp_nlo', ff_KAm='NNFF10_KAm_nlo'):\n",
    "        '''\n",
    "        Get data in proper format for neural network\n",
    "        '''\n",
    "        self.pdfData = lhapdf.mkPDF(pdfset)\n",
    "        self.ffDataPIp = lhapdf.mkPDF(ff_PIp, 0)\n",
    "        self.ffDataPIm = lhapdf.mkPDF(ff_PIm, 0)\n",
    "        self.ffDataPIsum = lhapdf.mkPDF(ff_PIsum, 0)\n",
    "        self.ffDataKAp = lhapdf.mkPDF(ff_KAp, 0)\n",
    "        self.ffDataKAm = lhapdf.mkPDF(ff_KAm, 0)\n",
    "        # needs to be extended to generalize for kaons\n",
    "        self.eu = 2/3\n",
    "        self.eubar = -2/3\n",
    "        self.ed = -1/3\n",
    "        self.edbar = 1/3\n",
    "        self.es = -1/3\n",
    "        self.esbar = 1/3\n",
    "        \n",
    "        self.ffDict = {0: self.ffDataPIp,\n",
    "                       1: self.ffDataPIm,\n",
    "                       2: self.ffDataPIsum,\n",
    "                       3: self.ffDataKAp,\n",
    "                       4: self.ffDataKAm}\n",
    "    \n",
    "\n",
    "    def pdf(self, flavor, x, QQ):\n",
    "        return np.array([self.pdfData.xfxQ2(flavor, ax, qq) for ax, qq in zip(x, QQ)])\n",
    "    \n",
    "    \n",
    "    def ff(self, func, flavor, z, QQ):\n",
    "        return np.array([func.xfxQ2(flavor, az, qq) for az, qq in zip(z, QQ)])    \n",
    "    \n",
    "\n",
    "    def makeData(self, df, hadrons, dependencies):\n",
    "        \n",
    "        data = {'x': [],\n",
    "             'z': [],\n",
    "             'phT': [],\n",
    "             'uexpr': [],\n",
    "             'ubarexpr': [],\n",
    "             'dexpr': [],\n",
    "             'dbarexpr': [],\n",
    "             'sexpr': [],\n",
    "             'sbarexpr': []}\n",
    "        \n",
    "        y = []\n",
    "        err = []\n",
    "        \n",
    "        df = df.loc[df['hadron'].isin(hadrons), :]\n",
    "        df = df.loc[df['1D_dependence'].isin(dependencies), :]\n",
    "        #X = np.array(df[['x', 'z', 'phT', 'Q2', 'hadron']])\n",
    "        for i, had in enumerate(['pi+', 'pi-', 'pi0', 'k+', 'k-']):\n",
    "            sliced = df.loc[df['hadron'] == had, :]\n",
    "            y += list(sliced['Siv'])\n",
    "            err += list(sliced['tot_err'])\n",
    "            \n",
    "            x = sliced['x']\n",
    "            z = sliced['z']\n",
    "            QQ = sliced['Q2']\n",
    "            data['uexpr'] += list(self.eu**2 * self.pdf(2, x, QQ) * self.ff(self.ffDict[i], 2, z, QQ))\n",
    "            data['ubarexpr'] += list(self.eubar**2 * self.pdf(-2, x, QQ) * self.ff(self.ffDict[i], -2, z, QQ))\n",
    "            data['dexpr'] += list(self.ed**2 * self.pdf(1, x, QQ) * self.ff(self.ffDict[i], 1, z, QQ))\n",
    "            data['dbarexpr'] += list(self.edbar**2 * self.pdf(-1, x, QQ) * self.ff(self.ffDict[i], -1, z, QQ))\n",
    "            data['sexpr'] += list(self.es**2 * self.pdf(3, x, QQ) * self.ff(self.ffDict[i], 3, z, QQ))\n",
    "            data['sbarexpr'] += list(self.esbar**2 * self.pdf(-3, x, QQ) * self.ff(self.ffDict[i], -3, z, QQ))\n",
    "\n",
    "            data['x'] += list(x)\n",
    "            data['z'] += list(z)\n",
    "            data['phT'] += list(sliced['phT'])\n",
    "        \n",
    "        for key in data.keys():\n",
    "            data[key] = np.array(data[key])\n",
    "        \n",
    "        print(data)\n",
    "        return data, np.array(y), np.array(err)                      \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Data(num_points):\n",
    "    \"\"\"\n",
    "    num_points will be the data points for each hadron\n",
    "    \n",
    "    \"\"\"\n",
    "    data_dictionary={\"hadron\":[],\"x\":[],\"z\":[],\"phT\":[],\"Q2\":[],\"Siv\":[],\"tot_err\":[]}\n",
    "    data_dictionary[\"x\"]=np.random.uniform(0.01,0.9,size=num_points)\n",
    "    data_dictionary[\"z\"]=np.random.uniform(0.2,0.5,size=num_points)\n",
    "    data_dictionary[\"phT\"]=np.random.uniform(0.3,0.9,size=num_points)\n",
    "    data_dictionary[\"Q2\"]=np.random.uniform(1,10,size=num_points)\n",
    "    PiP=pd.DataFrame(data_dictionary)\n",
    "    PiM=pd.DataFrame(data_dictionary)\n",
    "    Pi0=pd.DataFrame(data_dictionary)\n",
    "    KP=pd.DataFrame(data_dictionary)\n",
    "    KM=pd.DataFrame(data_dictionary)\n",
    "    for i in range(num_points):\n",
    "        PiP=hskjfhk\n",
    "        PiM=\n",
    "        KP\n",
    "    df=Concatenate[PiP,PiM,Pi0,KP,KM]\n",
    "    return df\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
